<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>05 Linguistic Structure Dependency Parsing | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="对于句法结构(syntactic structure)分析，主要有两种方式：Constituency Parsing与Dependency Parsing Constituency ParsingConstituency Parsing主要用phrase structure grammer即短语语法来不断的将词语整理成嵌套的组成成分，又被称为context-free grammers，简写做CFG">
<meta property="og:type" content="article">
<meta property="og:title" content="05 Linguistic Structure Dependency Parsing">
<meta property="og:url" content="http://yoursite.com/2020/04/30/Linguistic%20Structure%20Dependency%20Parsing/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="对于句法结构(syntactic structure)分析，主要有两种方式：Constituency Parsing与Dependency Parsing Constituency ParsingConstituency Parsing主要用phrase structure grammer即短语语法来不断的将词语整理成嵌套的组成成分，又被称为context-free grammers，简写做CFG">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://yoursite.com/2020/04/30/Linguistic%20Structure%20Dependency%20Parsing/image01.png">
<meta property="og:image" content="http://yoursite.com/2020/04/30/Linguistic%20Structure%20Dependency%20Parsing/image02.png">
<meta property="og:image" content="http://yoursite.com/2020/04/30/Linguistic%20Structure%20Dependency%20Parsing/image03.png">
<meta property="og:image" content="http://yoursite.com/2020/04/30/Linguistic%20Structure%20Dependency%20Parsing/image04.png">
<meta property="og:image" content="http://yoursite.com/2020/04/30/Linguistic%20Structure%20Dependency%20Parsing/image05.png">
<meta property="og:image" content="http://yoursite.com/2020/04/30/Linguistic%20Structure%20Dependency%20Parsing/image06.png">
<meta property="article:published_time" content="2020-04-30T15:52:48.492Z">
<meta property="article:modified_time" content="2020-04-30T15:53:46.080Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="cs224n课程">
<meta property="article:tag" content="nlp">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/2020/04/30/Linguistic%20Structure%20Dependency%20Parsing/image01.png">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 4.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Linguistic Structure Dependency Parsing" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/04/30/Linguistic%20Structure%20Dependency%20Parsing/" class="article-date">
  <time datetime="2020-04-30T15:52:48.492Z" itemprop="datePublished">2020-04-30</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      05 Linguistic Structure Dependency Parsing
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>对于句法结构(syntactic structure)分析，主要有两种方式：Constituency Parsing与Dependency Parsing</p>
<h2 id="Constituency-Parsing"><a href="#Constituency-Parsing" class="headerlink" title="Constituency Parsing"></a>Constituency Parsing</h2><p>Constituency Parsing主要用phrase structure grammer即短语语法来不断的将词语整理成嵌套的组成成分，又被称为context-free grammers，简写做CFG<br>其主要步骤是先对每个词做词性分析part of speech, 简称POS，然后再将其组成短语，再将短语不断递归构成更大的短语</p>
<p><img src="/2020/04/30/Linguistic%20Structure%20Dependency%20Parsing/image01.png" alt></p>
<p>例如，对于 the cuddly cat by the door, 先做POS分析，the是限定词，用Det(Determiner)表示，cuddly是形容词，用Adj(Adjective)代表，cat和door是名词，用N(Noun)表示, by是介词，用P(Preposition)表示。<br>然后the cuddly cat构成名词短语NP(Noun Phrase)，这里由Det(the)+Adj(cuddly)+N(cat)构成，by the door构成介词短语PP(Preposition Phrase), 这里由P(by)+NP(the door)构成。<br>最后，整个短语the cuddly cat by the door 是NP，由NP（the cuddly cat）+ PP(by the door)构成。</p>
<h2 id="Dependency-Parsing"><a href="#Dependency-Parsing" class="headerlink" title="Dependency Parsing"></a>Dependency Parsing</h2><p>Dependency Structure展示了词语之前的依赖关系,通常用箭头表示其依存关系，有时也会在箭头上标出其具体的语法关系，如是主语还是宾语关系等。<br>Dependency Structure有两种表现形式，一种是直接在句子上标出依存关系箭头及语法关系，如 ：  </p>
<p><img src="/2020/04/30/Linguistic%20Structure%20Dependency%20Parsing/image02.png" alt></p>
<p>另一种是将其做成树状机构（Dependency Tree Graph）</p>
<p>Bills on ports and immigration were submitted by Senator Brownback, Republican of Kansas<br>堪萨斯州共和党参议员布朗巴克(Brownback)提交了有关港口和移民的法案</p>
<p><img src="/2020/04/30/Linguistic%20Structure%20Dependency%20Parsing/image03.png" alt></p>
<p>Dependency Parsing可以看做是给定输入句子$S=w_0w_1…w_n$（其中$w_0$常常是fake ROOT，使得句子中每一个词都依赖于另一个节点）构建对应的Dependency Tree Graph的任务。而这个树如何构建呢？一个有效的方法是Transition-based Dependency Parsing</p>
<h3 id="Transition-based-Dependency-Parsing"><a href="#Transition-based-Dependency-Parsing" class="headerlink" title="Transition-based Dependency Parsing"></a>Transition-based Dependency Parsing</h3><p>Transition-based Dependency Parsing可以看做是状态机，对于$S=w_0w_1…w_n$，其状态由三部分构成$(\sigma,\beta,A)$<br>$\sigma$是$S$中若干$w_i$构成的堆(stack)<br>$\beta$是$S$中若干$w_i$构成的缓冲(buffer)<br>$A$是$w_i$之间的关系依存弧构成的集合，每一条边的形式是$(w_i,r,w_j)$，其中$r$描述了节点的依存关系(如动宾关系等)<br>初始状态时，$\sigma$仅包含ROOT$w_0$，$\beta$包含了所有的单词$w_1…w_n$，而$A$是空集$\varnothing$。最终的目标是$\sigma$包含ROOTT$w_0$，$\beta$清空，而$A$包含了所有关系， $A$就是我们想要的描述Dependency的结果<br>其含义是对于$S$中所有的单词都找到了相互的关系<br>状态之间的转移有三类 ： </p>
<ul>
<li>移除在缓冲区的第一个单词，然后将其放在堆的顶部（前提条件：缓冲区不能为空）。</li>
<li>LEFT-ARC：向依存弧集合$A$中加入一个依存弧$(w_j,r,w_i)$，其中$w_i$是堆顶的第二个单词，$w_j$堆顶部的单词。从堆栈中移除$w_i$。</li>
<li>RIGHT-ARC:向依存弧集合$A$中加入一个依存弧$(w_i,r,w_j)，其中$w_i$是堆顶的第二个单词，$w_j$堆顶部的单词。从堆栈中移除$w_j$。<br>我们不断的进行上述三类操作，直到从初始态达到最终态。    </li>
</ul>
<p>在每个状态下如何选择哪种操作呢？  </p>
<ul>
<li>当我们考虑到LEFT-ARC与RIGHT-ARC各有|R|(|R|为r的类的个数)种类别，我们可以将其看做是类别数为2|R|+1的分类问题。</li>
<li>每一个stack+buffer的状态相当于输入，3种操作相当于输出，把这个问题建模成分类问题。于是Nivre等人对每一个stack+buffer的状态，人工抽取出很多的特征，然后使用logistic或者svm进行分类。但是，当时的特征设计都是0/1状态的，特征向量很稀疏；特征又多，抽取特征很花时间。</li>
</ul>
<h3 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h3><p>当我们有了Dependency Parsing的模型后，我们如何对其准确性进行评估呢？<br>我们有两个metric，一个是<strong>LAS(labeled attachment score)</strong>即只有arc的箭头方向以及语法关系均正确时才算正确，以及<strong>UAS(unlabeled attachment score)</strong>即只要arc的箭头方向正确即可。</p>
<p><img src="/2020/04/30/Linguistic%20Structure%20Dependency%20Parsing/image04.png" alt></p>
<h3 id="Neural-Dependency-Parsing"><a href="#Neural-Dependency-Parsing" class="headerlink" title="Neural Dependency Parsing"></a>Neural Dependency Parsing</h3><p>传统的Transition-based Dependency Parsing对特征工程要求较高，我们可以用神经网络来减少人力劳动</p>
<p>对于Neural Dependency Parser，其输入特征通常包含三种：</p>
<ul>
<li>stack和buffer中的单词及其dependent word。</li>
<li>单词的Part-of-Speech tag。</li>
<li>描述语法关系的arc label。</li>
</ul>
<p><img src="/2020/04/30/Linguistic%20Structure%20Dependency%20Parsing/image05.png" alt></p>
<p>当神经网络火了之后，人们自然想到了用神经网络替代logistic或svm，提出了新的句法分析器。他们对于每一个stack+buffer的状态，抽取出words、POS tags和arc labels三种不同类型的特征，都用词向量来表示。然后输入只有一个隐层的全连接网络，效果立马超过了之前所有人工设计的特征和方法。基于这个工作，后续又有很多改进版本。</p>
<p><img src="/2020/04/30/Linguistic%20Structure%20Dependency%20Parsing/image06.png" alt></p>
<p>利用这样简单的前置神经网络，我们就可以减少特征工程并提高准确度，当然，RNN模型也可以应用到Dependency Parsing任务中。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/04/30/Linguistic%20Structure%20Dependency%20Parsing/" data-id="ck9myomw40000hov86y5337an" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/cs224n%E8%AF%BE%E7%A8%8B/" rel="tag">cs224n课程</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/nlp/" rel="tag">nlp</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2020/04/30/The%20probability%20of%20a%20sentence%20Recurrent%20Neural%20Networks%20and%20Language%20Models/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          06 The probability of a sentence? Recurrent Neural Networks and Language Models
        
      </div>
    </a>
  
  
    <a href="/2020/04/30/Matrix%20Calculus%20and%20Backpropagation/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">04 Matrix Calculus and Backpropagation</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/cs224n%E8%AF%BE%E7%A8%8B/" rel="tag">cs224n课程</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/nlp/" rel="tag">nlp</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/cs224n%E8%AF%BE%E7%A8%8B/" style="font-size: 10px;">cs224n课程</a> <a href="/tags/nlp/" style="font-size: 10px;">nlp</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">四月 2020</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/04/30/The%20probability%20of%20a%20sentence%20Recurrent%20Neural%20Networks%20and%20Language%20Models/">06 The probability of a sentence? Recurrent Neural Networks and Language Models</a>
          </li>
        
          <li>
            <a href="/2020/04/30/Linguistic%20Structure%20Dependency%20Parsing/">05 Linguistic Structure Dependency Parsing</a>
          </li>
        
          <li>
            <a href="/2020/04/30/Matrix%20Calculus%20and%20Backpropagation/">04 Matrix Calculus and Backpropagation</a>
          </li>
        
          <li>
            <a href="/2020/04/30/Word%20Window%20Classification,%20Neural%20Networks,%20and%20PyTorch/">03 Word Window Classification, Neural Networks, and PyTorch</a>
          </li>
        
          <li>
            <a href="/2020/04/30/Introduction%20and%20Word%20Vectors/">01 Introduction and Word Vectors</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</body>
</html>